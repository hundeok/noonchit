// core/services/openai_service.dart
// ğŸ¤– OpenAI GPT ì—°ë™ ì„œë¹„ìŠ¤ - ë°”í…€ë¼ì¸ ìƒì„±

import 'dart:async';
import 'dart:convert';
import 'package:flutter/foundation.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:http/http.dart' as http;

import '../utils/bottom_line_constants.dart';
import '../utils/logger.dart';
import '../../domain/entities/bottom_line.dart';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”§ OpenAI API ì‘ë‹µ ëª¨ë¸ë“¤
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// OpenAI API ì‘ë‹µ ëª¨ë¸
@immutable
class OpenAIResponse {
  final List<String> headlines;
  final String model;
  final int tokensUsed;
  final Duration processingTime;
  final bool isFromCache;

  const OpenAIResponse({
    required this.headlines,
    required this.model,
    required this.tokensUsed,
    required this.processingTime,
    this.isFromCache = false,
  });

  factory OpenAIResponse.fromJson(Map<String, dynamic> json, Duration processingTime) {
    final choices = json['choices'] as List<dynamic>? ?? [];
    final usage = json['usage'] as Map<String, dynamic>? ?? {};
    
    // GPT ì‘ë‹µì—ì„œ í—¤ë“œë¼ì¸ ì¶”ì¶œ
    final headlines = <String>[];
    for (final choice in choices) {
      final content = choice['message']?['content'] as String? ?? '';
      if (content.isNotEmpty) {
        // ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬ëœ í—¤ë“œë¼ì¸ë“¤ íŒŒì‹±
        final lines = content.split('\n')
          .map((line) => line.trim())
          .where((line) => line.isNotEmpty && !line.startsWith('//'))
          .toList();
        headlines.addAll(lines);
      }
    }
    
    return OpenAIResponse(
      headlines: headlines,
      model: json['model'] as String? ?? 'unknown',
      tokensUsed: usage['total_tokens'] as int? ?? 0,
      processingTime: processingTime,
    );
  }

  /// ìºì‹œëœ ì‘ë‹µ ìƒì„±
  factory OpenAIResponse.cached(List<String> headlines) {
    return OpenAIResponse(
      headlines: headlines,
      model: 'cached',
      tokensUsed: 0,
      processingTime: Duration.zero,
      isFromCache: true,
    );
  }

  @override
  String toString() {
    return 'OpenAIResponse(${headlines.length} headlines, $model, $tokensUsed tokens, ${processingTime.inMilliseconds}ms, cached: $isFromCache)';
  }
}

/// OpenAI API ì—ëŸ¬ ëª¨ë¸
@immutable
class OpenAIError {
  final String message;
  final String? code;
  final int? statusCode;
  final bool isRetryable;

  const OpenAIError({
    required this.message,
    this.code,
    this.statusCode,
    this.isRetryable = false,
  });

  factory OpenAIError.fromJson(Map<String, dynamic> json) {
    final error = json['error'] as Map<String, dynamic>? ?? {};
    
    return OpenAIError(
      message: error['message'] as String? ?? 'Unknown error',
      code: error['code'] as String?,
      statusCode: json['status_code'] as int?,
      isRetryable: _isRetryableError(error['code'] as String?),
    );
  }

  static bool _isRetryableError(String? code) {
    // ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ ì½”ë“œë“¤
    const retryableCodes = [
      'rate_limit_exceeded',
      'server_error',
      'timeout',
      'insufficient_quota',
    ];
    return code != null && retryableCodes.contains(code);
  }

  @override
  String toString() {
    return 'OpenAIError($code: $message, retryable: $isRetryable)';
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¤– OpenAI ì„œë¹„ìŠ¤ ë©”ì¸ í´ë˜ìŠ¤
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// OpenAI GPT ê¸°ë°˜ ë°”í…€ë¼ì¸ ìƒì„± ì„œë¹„ìŠ¤
class OpenAIService {
  // ğŸ”‘ API ì„¤ì •
  static const String _baseUrl = 'https://api.openai.com/v1';
  static const String _chatEndpoint = '/chat/completions';
  static const String _model = 'gpt-4o-mini'; // ë¹„ìš© íš¨ìœ¨ì  ëª¨ë¸
  static const int _maxRetries = 3;
  
  // ğŸ“Š í†µê³„ ë° ìºì‹œ
  final Map<String, List<String>> _responseCache = {};
  final Map<String, DateTime> _cacheTimestamps = {};
  int _totalRequests = 0;
  int _successfulRequests = 0;
  int _cachedResponses = 0;
  int _failedRequests = 0;
  Duration _totalResponseTime = const Duration();
  
  // ğŸ”§ HTTP í´ë¼ì´ì–¸íŠ¸
  late final http.Client _httpClient;
  
  /// API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
  final String _apiKey;
  
  OpenAIService({String? apiKey}) 
    : _apiKey = apiKey ?? _getApiKeyFromEnvironment(),
      _httpClient = http.Client() {
    
    if (_apiKey.isEmpty) {
      log.w('âš ï¸ OpenAI API key not found. Service will use fallback mode.');
    }
    
    if (BottomLineConstants.enableAILogging) {
      log.i('ğŸ¤– OpenAI Service initialized with gpt-4o-mini');
    }
  }

  static String _getApiKeyFromEnvironment() {
    // .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
    try {
      return dotenv.env['OPENAI_API_KEY'] ?? '';
    } catch (e) {
      log.e('Failed to load .env file: $e');
      return '';
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ¯ ë©”ì¸ ë°”í…€ë¼ì¸ ìƒì„± ë©”ì„œë“œ
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// ì¸ì‚¬ì´íŠ¸ ëª©ë¡ì„ ESPN ìŠ¤íƒ€ì¼ ë°”í…€ë¼ì¸ìœ¼ë¡œ ë³€í™˜
  Future<List<String>> generateBottomLines(List<CandidateInsight> insights) async {
    if (insights.isEmpty) {
      return _getFallbackMessages();
    }
    
    if (_apiKey.isEmpty) {
      log.w('ğŸ›¡ï¸ No API key - using fallback mode');
      return _generateFallbackFromInsights(insights);
    }
    
    try {
      // ğŸ” ìºì‹œ í™•ì¸
      final cacheKey = _generateCacheKey(insights);
      final cachedResponse = _getFromCache(cacheKey);
      if (cachedResponse != null) {
        _cachedResponses++;
        return cachedResponse;
      }
      
      // ğŸ¤– AI í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
      final response = await _callOpenAIWithRetry(insights);
      
      // ğŸ“ ì‘ë‹µ ì²˜ë¦¬
      final headlines = _processResponse(response, insights);
      
      // ğŸ’¾ ìºì‹œ ì €ì¥
      _saveToCache(cacheKey, headlines);
      
      // ğŸ“Š í†µê³„ ì—…ë°ì´íŠ¸
      _updateStats(true, response.processingTime);
      
      if (BottomLineConstants.enableAILogging) {
        log.d('ğŸ¤– Generated ${headlines.length} headlines: $response');
      }
      
      return headlines;
      
    } catch (e, stackTrace) {
      log.e('ğŸš¨ OpenAI generation failed: $e', e, stackTrace);
      
      _updateStats(false, const Duration());
      
      // ì‹¤íŒ¨ ì‹œ í…œí”Œë¦¿ ê¸°ë°˜ ëŒ€ì²´
      return _generateFallbackFromInsights(insights);
    }
  }

  /// ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ OpenAI API í˜¸ì¶œ
  Future<OpenAIResponse> _callOpenAIWithRetry(List<CandidateInsight> insights) async {
    Exception? lastException;
    
    for (int retry = 0; retry < _maxRetries; retry++) {
      try {
        if (retry > 0) {
          // ì§€ìˆ˜ ë°±ì˜¤í”„ ëŒ€ê¸°
          final delay = Duration(seconds: (retry * 2));
          await Future.delayed(delay);
          log.d('ğŸ”„ Retrying OpenAI call (${retry + 1}/$_maxRetries)');
        }
        
        return await _callOpenAI(insights);
        
      } catch (e) {
        lastException = e is Exception ? e : Exception('$e');
        
        // ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬ë©´ ì¦‰ì‹œ ì¢…ë£Œ
        if (e.toString().contains('invalid_api_key') || 
            e.toString().contains('insufficient_quota')) {
          break;
        }
        
        log.w('âš ï¸ OpenAI call failed (attempt ${retry + 1}): $e');
      }
    }
    
    throw lastException ?? Exception('Max retries exceeded');
  }

  /// OpenAI API í˜¸ì¶œ
  Future<OpenAIResponse> _callOpenAI(List<CandidateInsight> insights) async {
    final stopwatch = Stopwatch()..start();
    
    try {
      // ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìµœì í™”ëœ ë²„ì „)
      final prompt = _buildOptimizedPrompt(insights);
      
      // ğŸŒ HTTP ìš”ì²­
      final response = await _httpClient
        .post(
          Uri.parse('$_baseUrl$_chatEndpoint'),
          headers: _buildHeaders(),
          body: jsonEncode(_buildRequestBody(prompt)),
        )
        .timeout(const Duration(seconds: 30));
      
      stopwatch.stop();
      
      // ğŸ“Š ì‘ë‹µ ì²˜ë¦¬
      if (response.statusCode == 200) {
        final jsonResponse = jsonDecode(response.body) as Map<String, dynamic>;
        return OpenAIResponse.fromJson(jsonResponse, stopwatch.elapsed);
      } else {
        final errorJson = jsonDecode(response.body) as Map<String, dynamic>;
        final error = OpenAIError.fromJson(errorJson);
        throw Exception('OpenAI API error: $error');
      }
      
    } on TimeoutException {
      stopwatch.stop();
      throw Exception('OpenAI API timeout after 30s');
    } on http.ClientException catch (e) {
      stopwatch.stop();
      throw Exception('Network error: $e');
    }
  }

  /// ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (í† í° ì ˆì•½)
  String _buildOptimizedPrompt(List<CandidateInsight> insights) {
    final hasUrgent = insights.any((i) => i.isHighPriority);
    
    final prompt = StringBuffer();
    
    // ê°„ê²°í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    prompt.writeln('ESPN ìŠ¤íƒ€ì¼ ì•”í˜¸í™”í ì†ë³´ë¥¼ ìƒì„±í•˜ì„¸ìš”.');
    prompt.writeln('ìš”êµ¬ì‚¬í•­: 15-30ë‹¨ì–´, êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨, ì´ëª¨ì§€ 1-2ê°œ');
    
    if (hasUrgent) {
      prompt.writeln('âš ï¸ ê¸´ê¸‰ ìƒí™© í¬í•¨ - ê°•ë ¬í•˜ê²Œ ì‘ì„±');
    }
    
    prompt.writeln('\nì˜ˆì‹œ:');
    prompt.writeln('ğŸ”¥ BTC 3ë¶„ ì—°ì† ìƒìŠ¹ì„¸, 1600ë§Œì› ëŒíŒŒ');
    prompt.writeln('âš¡ AI ì„¹í„° ê±°ë˜ëŸ‰ ì „ì¼æ¯” 340% í­ì¦');
    
    // ì¸ì‚¬ì´íŠ¸ ë°ì´í„° (ê°„ê²°í•˜ê²Œ)
    prompt.writeln('\ní˜„ì¬ ì¸ì‚¬ì´íŠ¸:');
    for (int i = 0; i < insights.length && i < 5; i++) { // ìµœëŒ€ 5ê°œë§Œ
      final insight = insights[i];
      final priority = insight.isHighPriority ? '[ê¸´ê¸‰]' : '';
      prompt.writeln('${i + 1}. $priority${insight.populatedTemplate}');
    }
    
    prompt.writeln('\nìœ„ë¥¼ ESPN ìŠ¤íƒ€ì¼ í—¤ë“œë¼ì¸ ${insights.length.clamp(1, 5)}ê°œë¡œ ë³€í™˜:');
    
    return prompt.toString();
  }

  /// HTTP í—¤ë” ìƒì„±
  Map<String, String> _buildHeaders() {
    return {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer $_apiKey',
      'User-Agent': 'BottomLine/1.0.0',
    };
  }

  /// ìš”ì²­ ë³¸ë¬¸ ìƒì„± (ìµœì í™”ëœ ì„¤ì •)
  Map<String, dynamic> _buildRequestBody(String prompt) {
    return {
      'model': _model,
      'messages': [
        {
          'role': 'system',
          'content': 'ì „ë¬¸ ê¸ˆìœµ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ì‘ì„±ì',
        },
        {
          'role': 'user',
          'content': prompt,
        },
      ],
      'max_tokens': 300, // í† í° ì ˆì•½
      'temperature': 0.7,
      'top_p': 0.9,
      'frequency_penalty': 0.3,
      'presence_penalty': 0.1,
    };
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ”„ ì‘ë‹µ ì²˜ë¦¬ ë° í›„ì²˜ë¦¬
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// OpenAI ì‘ë‹µ ì²˜ë¦¬ ë° ê²€ì¦
  List<String> _processResponse(OpenAIResponse response, List<CandidateInsight> insights) {
    if (response.headlines.isEmpty) {
      log.w('âš ï¸ OpenAI returned empty headlines');
      return _generateFallbackFromInsights(insights);
    }
    
    // í—¤ë“œë¼ì¸ ì •ì œ ë° ê²€ì¦
    final processedHeadlines = response.headlines
      .map((headline) => _sanitizeHeadline(headline))
      .where((headline) => _isValidHeadline(headline))
      .take(5) // ìµœëŒ€ 5ê°œ
      .toList();
    
    // ë¶€ì¡±í•œ ê²½ìš° í…œí”Œë¦¿ìœ¼ë¡œ ë³´ì™„
    while (processedHeadlines.length < 3 && 
           processedHeadlines.length < insights.length) {
      final remainingInsights = insights.skip(processedHeadlines.length).toList();
      if (remainingInsights.isNotEmpty) {
        processedHeadlines.add(remainingInsights.first.populatedTemplate);
      } else {
        break;
      }
    }
    
    return processedHeadlines;
  }

  /// í—¤ë“œë¼ì¸ ì •ì œ (ê°œì„ ëœ íŒŒì‹±)
  String _sanitizeHeadline(String headline) {
    // ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±° (ê°œì„ ëœ ì •ê·œì‹)
    String cleaned = headline
      .replaceAll(RegExp(r'^[-*\d.]+\s*'), '') // ëª¨ë“  bullet point ì œê±°
      .replaceAll(RegExp(r'["""]'), '"')       // ë”°ì˜´í‘œ í†µì¼
      .trim();
    
    // ê¸¸ì´ ì œí•œ
    if (cleaned.length > 100) {
      cleaned = '${cleaned.substring(0, 97)}...';
    }
    
    return cleaned;
  }

  /// í—¤ë“œë¼ì¸ ìœ íš¨ì„± ê²€ì¦
  bool _isValidHeadline(String headline) {
    // ìµœì†Œ ê¸¸ì´ ì²´í¬
    if (headline.length < 10) {
      return false;
    }
    
    // ê¸ˆì§€ëœ ë‹¨ì–´ë‚˜ íŒ¨í„´ ì²´í¬
    const forbiddenPatterns = [
      'error', 'failed', 'undefined', 'null', '####', '***',
    ];
    
    final lowerHeadline = headline.toLowerCase();
    for (final pattern in forbiddenPatterns) {
      if (lowerHeadline.contains(pattern)) {
        return false;
      }
    }
    
    // ê¸°ë³¸ì ì¸ í•œê¸€/ì˜ì–´/ìˆ«ì í¬í•¨ ì—¬ë¶€
    if (!RegExp(r'[ê°€-í£a-zA-Z0-9]').hasMatch(headline)) {
      return false;
    }
    
    return true;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ’¾ ìºì‹± ì‹œìŠ¤í…œ
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// ìºì‹œ í‚¤ ìƒì„±
  String _generateCacheKey(List<CandidateInsight> insights) {
    final keyData = insights
      .take(3) // ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
      .map((i) => '${i.id}_${i.finalScore.toStringAsFixed(1)}')
      .join('|');
    return keyData.hashCode.toString();
  }

  /// ìºì‹œì—ì„œ ì¡°íšŒ
  List<String>? _getFromCache(String key) {
    final cached = _responseCache[key];
    final timestamp = _cacheTimestamps[key];
    
    if (cached != null && timestamp != null) {
      // 3ë¶„ ì´ë‚´ ìºì‹œë§Œ ìœ íš¨ (ë” ì§§ê²Œ)
      final age = DateTime.now().difference(timestamp);
      if (age.inMinutes < 3) {
        return cached;
      } else {
        _responseCache.remove(key);
        _cacheTimestamps.remove(key);
      }
    }
    
    return null;
  }

  /// ìºì‹œì— ì €ì¥
  void _saveToCache(String key, List<String> headlines) {
    _responseCache[key] = headlines;
    _cacheTimestamps[key] = DateTime.now();
    
    // ìºì‹œ í¬ê¸° ì œí•œ (ìµœëŒ€ 20ê°œ)
    if (_responseCache.length > 20) {
      final oldestKey = _cacheTimestamps.entries
        .reduce((a, b) => a.value.isBefore(b.value) ? a : b)
        .key;
      
      _responseCache.remove(oldestKey);
      _cacheTimestamps.remove(oldestKey);
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ›¡ï¸ ì—ëŸ¬ ì²˜ë¦¬ ë° ëŒ€ì²´ ì‹œìŠ¤í…œ
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// í…œí”Œë¦¿ ê¸°ë°˜ ëŒ€ì²´ í—¤ë“œë¼ì¸ ìƒì„±
  List<String> _generateFallbackFromInsights(List<CandidateInsight> insights) {
    if (BottomLineConstants.enableAILogging) {
      log.d('ğŸ›¡ï¸ Generating fallback headlines from ${insights.length} insights');
    }
    
    return insights
      .take(3) // ìµœëŒ€ 3ê°œ
      .map((insight) => _enhanceTemplate(insight.populatedTemplate))
      .toList();
  }

  /// í…œí”Œë¦¿ í–¥ìƒ (ì´ëª¨ì§€ ì¶”ê°€)
  String _enhanceTemplate(String template) {
    // ì´ë¯¸ ì´ëª¨ì§€ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
    if (RegExp(r'[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]', 
               unicode: true).hasMatch(template)) {
      return template;
    }
    
    // í‚¤ì›Œë“œì— ë”°ë¼ ì´ëª¨ì§€ ì¶”ê°€
    if (template.contains('ëŒ€í˜•ë§¤ìˆ˜') || template.contains('ê³ ì•¡ê±°ë˜')) {
      return 'ğŸ”¥ $template';
    } else if (template.contains('ê±°ë˜ëŸ‰') || template.contains('ë³¼ë¥¨')) {
      return 'âš¡ $template';
    } else if (template.contains('ê¸‰ë“±') || template.contains('ìƒìŠ¹')) {
      return 'ğŸ“ˆ $template';
    } else if (template.contains('ì„¹í„°') || template.contains('ìê¸ˆ')) {
      return 'ğŸ’« $template';
    } else {
      return 'ğŸ“Š $template';
    }
  }

  /// ê¸°ë³¸ ëŒ€ì²´ ë©”ì‹œì§€ë“¤
  List<String> _getFallbackMessages() {
    const messages = [
      'ğŸ“Š ì•”í˜¸í™”í ì‹œì¥ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¤‘',
      'ğŸ’° ê³ ì•¡ê±°ë˜ íŒ¨í„´ ë¶„ì„ ì§„í–‰ ì¤‘', 
      'âš¡ ê±°ë˜ëŸ‰ ê¸‰ì¦ ì½”ì¸ ìŠ¤ìº” ì¤‘',
    ];
    
    return messages.toList();
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ“Š í†µê³„ ë° ëª¨ë‹ˆí„°ë§
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// í†µê³„ ì—…ë°ì´íŠ¸
  void _updateStats(bool success, Duration responseTime) {
    _totalRequests++;
    _totalResponseTime += responseTime;
    
    if (success) {
      _successfulRequests++;
    } else {
      _failedRequests++;
    }
  }

  /// ì„œë¹„ìŠ¤ í†µê³„ ì¡°íšŒ
  Map<String, dynamic> getStats() {
    final successRate = _totalRequests > 0 
      ? _successfulRequests / _totalRequests 
      : 0.0;
    
    final avgResponseTime = _totalRequests > 0
      ? _totalResponseTime.inMilliseconds / _totalRequests
      : 0.0;
    
    final cacheHitRate = _totalRequests > 0
      ? _cachedResponses / _totalRequests
      : 0.0;
    
    return {
      'total_requests': _totalRequests,
      'successful_requests': _successfulRequests,
      'failed_requests': _failedRequests,
      'cached_responses': _cachedResponses,
      'success_rate': '${(successRate * 100).toStringAsFixed(1)}%',
      'cache_hit_rate': '${(cacheHitRate * 100).toStringAsFixed(1)}%',
      'avg_response_time_ms': avgResponseTime.toStringAsFixed(1),
      'cache_size': _responseCache.length,
      'api_key_configured': _apiKey.isNotEmpty,
      'model': _model,
    };
  }

  /// ì—°ê²° í…ŒìŠ¤íŠ¸
  Future<bool> testConnection() async {
    if (_apiKey.isEmpty) {
      log.w('âš ï¸ No API key configured');
      return false;
    }
    
    try {
      final testInsights = [
        CandidateInsight(
          id: 'test',
          template: 'BTC í…ŒìŠ¤íŠ¸ ê±°ë˜ ê°ì§€',
          score: 1.5,
          weight: 1.0,
          templateVars: {'market': 'KRW-BTC'},
          timestamp: DateTime.now(),
        ),
      ];
      
      final result = await generateBottomLines(testInsights);
      return result.isNotEmpty;
      
    } catch (e) {
      log.e('ğŸš¨ OpenAI connection test failed: $e');
      return false;
    }
  }

  /// ìºì‹œ ì •ë¦¬
  void clearCache() {
    _responseCache.clear();
    _cacheTimestamps.clear();
    
    if (BottomLineConstants.enableAILogging) {
      log.d('ğŸ—‘ï¸ OpenAI cache cleared');
    }
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _httpClient.close();
    clearCache();
    
    if (BottomLineConstants.enableAILogging) {
      log.d('ğŸ›‘ OpenAI Service disposed');
    }
  }
}